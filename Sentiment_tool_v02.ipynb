{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be55a9-fd8f-48c7-8225-786333e3998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas textblob tqdm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "\n",
    "# NLTK (Natural Language Toolkit) is being imported and used to download language data needed for sentiment analysis.\n",
    "nltk.download('brown')  # Downloads a sample corpus of texts\n",
    "nltk.download('punkt')  # Downloads a tokenizer that divides a text into sentences or words\n",
    "nltk.download('averaged_perceptron_tagger')  # Downloads a model for part-of-speech tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a84040-e3e5-417e-8195-08f8e1e02642",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Read the CSV file:\n",
    "# Pandas' `read_csv()` function is used to load the CSV file into a DataFrame (df). \n",
    "# It assumes that the CSV file 'input.csv' is in the same directory.\n",
    "df = pd.read_csv('input.csv')\n",
    "\n",
    "# 2. Print column names to check if 'Body' exists:\n",
    "# We print the column names from the loaded DataFrame. This is useful for debugging\n",
    "# to ensure that the 'Body' column (which contains the text for sentiment analysis) exists.\n",
    "print(\"Columns in CSV:\", df.columns)\n",
    "\n",
    "# 3. Create empty DataFrames for clean data and quarantine data:\n",
    "# We create two empty DataFrames, `clean_df` for storing rows with acceptable content\n",
    "# and `quarantine_df` for rows with unsavory content.\n",
    "# These DataFrames have the same structure as the original `df` because we pass `df.columns` to the constructor.\n",
    "clean_df = pd.DataFrame(columns=df.columns)\n",
    "quarantine_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# 4. Iterate over each row of the DataFrame with a progress bar:\n",
    "# `tqdm` provides a progress bar for long loops. This is helpful for visual feedback during processing.\n",
    "# `iterrows()` allows us to iterate through each row of the DataFrame.\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "    \n",
    "    # 5. Get the 'Body' text for sentiment analysis:\n",
    "    # `row.get('Body')` safely gets the 'Body' column's value in the current row.\n",
    "    # `get()` ensures that if the column doesn't exist, it won't throw an error (returns None instead).\n",
    "    text = row.get('Body')  # 'Body' should contain the text content of interest\n",
    "    \n",
    "    # 6. Check if the text is a valid string and not NaN:\n",
    "    # We check if the value in 'Body' is a valid string. Sometimes, the CSV might have missing values (NaNs),\n",
    "    # and we don't want to analyze those. If `text` is a string, it proceeds to sentiment analysis.\n",
    "    if isinstance(text, str):\n",
    "        \n",
    "        # 7. Perform sentiment analysis using TextBlob:\n",
    "        # TextBlob is used here for simple sentiment analysis. It computes the polarity of the text.\n",
    "        # `analysis.sentiment.polarity` returns a float between -1 and 1, where -1 indicates extremely negative,\n",
    "        # 0 indicates neutral, and 1 indicates extremely positive sentiment.\n",
    "        analysis = TextBlob(text)\n",
    "        sentiment = analysis.sentiment.polarity\n",
    "        # print(f\"Row {index} sentiment: {sentiment}\")  # Debug print\n",
    "        \n",
    "        # 8. Check if the sentiment is unsavory (less than -0.1):\n",
    "        # This condition checks if the sentiment polarity is below a threshold (e.g., -0.1),\n",
    "        # which we consider as unsavory. If it is, the row is added to the `quarantine_df`.\n",
    "        # We use `pd.concat()` to add the row to the `quarantine_df` DataFrame.\n",
    "        if sentiment < -0.4:  \n",
    "            quarantine_df = pd.concat([quarantine_df, pd.DataFrame([row])], ignore_index=True)\n",
    "            # print(f\"Row {index} moved to quarantine.\")  # Debug print            \n",
    "        else:\n",
    "            # 9. If the sentiment is acceptable, add the row to the `clean_df`:\n",
    "            # If the sentiment is not below the threshold, it means the content is acceptable, \n",
    "            # and the row is added to the `clean_df`.\n",
    "            clean_df = pd.concat([clean_df, pd.DataFrame([row])], ignore_index=True)\n",
    "            # print(f\"Row {index} is clean.\")  # Debug print\n",
    "    \n",
    "    # 10. Handle cases where the text is missing or not valid:\n",
    "    # If the 'Body' value isn't a valid string (e.g., it might be NaN), we assume it's unsavory,\n",
    "    # and move the row to the `quarantine_df` for further analysis.\n",
    "    else:\n",
    "        quarantine_df = pd.concat([quarantine_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        # print(f\"Row {index} has no valid text, moved to quarantine.\")  # Debug print\n",
    "\n",
    "\n",
    "# 11. Print the number of rows in each DataFrame:\n",
    "# After the loop finishes, we print the number of rows in both `quarantine_df` and `clean_df`.\n",
    "# This ensures that rows are being processed and assigned correctly.\n",
    "print(f\"Number of rows in quarantine: {len(quarantine_df)}\")\n",
    "print(f\"Number of rows in clean data: {len(clean_df)}\")\n",
    "\n",
    "# 12. Write the quarantine data to a CSV file:\n",
    "# This saves the `quarantine_df` to a file named 'quarantine.csv'. Each row flagged as unsavory\n",
    "# will be written into this file.\n",
    "quarantine_df.to_csv('quarantine.csv', index=False)\n",
    "print(\"Quarantine file written successfully.\")\n",
    "\n",
    "# 13. Write the clean data to another CSV file:\n",
    "# Similarly, the `clean_df` is saved to 'cleaned.csv', containing all rows that passed the sentiment analysis.\n",
    "clean_df.to_csv('cleaned.csv', index=False)\n",
    "print(\"Cleaned file written successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
