{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae50a15f-c1db-45b5-a8b9-3cb4309a4b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: textblob in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: tqdm in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (4.66.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: nltk>=3.8 in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (from nltk>=3.8->textblob) (2024.4.16)\n",
      "Requirement already satisfied: six>=1.5 in /home/quana/anaconda3/envs/ds_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/quana/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/quana/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/quana/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install pandas textblob tqdm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "\n",
    "# NLTK (Natural Language Toolkit) is being imported and used to download language data needed for sentiment analysis.\n",
    "nltk.download('brown')  # Downloads a sample corpus of texts\n",
    "nltk.download('punkt')  # Downloads a tokenizer that divides a text into sentences or words\n",
    "nltk.download('averaged_perceptron_tagger')  # Downloads a model for part-of-speech tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4362d0aa-291d-48e4-8d1f-8e1e8f8089e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in CSV: Index(['Id', 'Body', 'Sentiment Type'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 2000/2000 [00:02<00:00, 956.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in quarantine: 293\n",
      "Number of rows in clean data: 1707\n",
      "Quarantine file written successfully.\n",
      "Cleaned file written successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Read the CSV file:\n",
    "# Pandas' `read_csv()` function is used to load the CSV file into a DataFrame (df). \n",
    "# It assumes that the CSV file 'input.csv' is in the same directory.\n",
    "df = pd.read_csv('input.csv')\n",
    "\n",
    "# 2. Print column names to check if 'Body' exists:\n",
    "# We print the column names from the loaded DataFrame. This is useful for debugging\n",
    "# to ensure that the 'Body' column (which contains the text for sentiment analysis) exists.\n",
    "print(\"Columns in CSV:\", df.columns)\n",
    "\n",
    "# 3. Create empty DataFrames for clean data and quarantine data:\n",
    "# We create two empty DataFrames, `clean_df` for storing rows with acceptable content\n",
    "# and `quarantine_df` for rows with unsavory content.\n",
    "# These DataFrames have the same structure as the original `df` because we pass `df.columns` to the constructor.\n",
    "clean_df = pd.DataFrame(columns=df.columns)\n",
    "quarantine_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# 4. Iterate over each row of the DataFrame with a progress bar:\n",
    "# `tqdm` provides a progress bar for long loops. This is helpful for visual feedback during processing.\n",
    "# `iterrows()` allows us to iterate through each row of the DataFrame.\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "    \n",
    "    # 5. Get the 'Body' text for sentiment analysis:\n",
    "    # `row.get('Body')` safely gets the 'Body' column's value in the current row.\n",
    "    # `get()` ensures that if the column doesn't exist, it won't throw an error (returns None instead).\n",
    "    text = row.get('Body')  # 'Body' should contain the text content of interest\n",
    "    \n",
    "    # 6. Check if the text is a valid string and not NaN:\n",
    "    # We check if the value in 'Body' is a valid string. Sometimes, the CSV might have missing values (NaNs),\n",
    "    # and we don't want to analyze those. If `text` is a string, it proceeds to sentiment analysis.\n",
    "    if isinstance(text, str):\n",
    "        \n",
    "        # 7. Perform sentiment analysis using TextBlob:\n",
    "        # TextBlob is used here for simple sentiment analysis. It computes the polarity of the text.\n",
    "        # `analysis.sentiment.polarity` returns a float between -1 and 1, where -1 indicates extremely negative,\n",
    "        # 0 indicates neutral, and 1 indicates extremely positive sentiment.\n",
    "        analysis = TextBlob(text)\n",
    "        sentiment = analysis.sentiment.polarity\n",
    "        # print(f\"Row {index} sentiment: {sentiment}\")  # Debug print\n",
    "        \n",
    "        # 8. Check if the sentiment is unsavory (less than -0.1):\n",
    "        # This condition checks if the sentiment polarity is below a threshold (e.g., -0.1),\n",
    "        # which we consider as unsavory. If it is, the row is added to the `quarantine_df`.\n",
    "        # We use `pd.concat()` to add the row to the `quarantine_df` DataFrame.\n",
    "        if sentiment < -0.4:  \n",
    "            quarantine_df = pd.concat([quarantine_df, pd.DataFrame([row])], ignore_index=True)\n",
    "            # print(f\"Row {index} moved to quarantine.\")  # Debug print            \n",
    "        else:\n",
    "            # 9. If the sentiment is acceptable, add the row to the `clean_df`:\n",
    "            # If the sentiment is not below the threshold, it means the content is acceptable, \n",
    "            # and the row is added to the `clean_df`.\n",
    "            clean_df = pd.concat([clean_df, pd.DataFrame([row])], ignore_index=True)\n",
    "            # print(f\"Row {index} is clean.\")  # Debug print\n",
    "    \n",
    "    # 10. Handle cases where the text is missing or not valid:\n",
    "    # If the 'Body' value isn't a valid string (e.g., it might be NaN), we assume it's unsavory,\n",
    "    # and move the row to the `quarantine_df` for further analysis.\n",
    "    else:\n",
    "        quarantine_df = pd.concat([quarantine_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        # print(f\"Row {index} has no valid text, moved to quarantine.\")  # Debug print\n",
    "\n",
    "\n",
    "# 11. Print the number of rows in each DataFrame:\n",
    "# After the loop finishes, we print the number of rows in both `quarantine_df` and `clean_df`.\n",
    "# This ensures that rows are being processed and assigned correctly.\n",
    "print(f\"Number of rows in quarantine: {len(quarantine_df)}\")\n",
    "print(f\"Number of rows in clean data: {len(clean_df)}\")\n",
    "\n",
    "# 12. Write the quarantine data to a CSV file:\n",
    "# This saves the `quarantine_df` to a file named 'quarantine.csv'. Each row flagged as unsavory\n",
    "# will be written into this file.\n",
    "quarantine_df.to_csv('quarantine.csv', index=False)\n",
    "print(\"Quarantine file written successfully.\")\n",
    "\n",
    "# 13. Write the clean data to another CSV file:\n",
    "# Similarly, the `clean_df` is saved to 'cleaned.csv', containing all rows that passed the sentiment analysis.\n",
    "clean_df.to_csv('cleaned.csv', index=False)\n",
    "print(\"Cleaned file written successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be55a9-fd8f-48c7-8225-786333e3998e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
